#
# Bug#35221441: FLUSH TABLE FOR EXPORT might lead to deadlock
# When gtid mode is on and there are concurrent DROP TABLE and FLUSH TABLE then
# there was a possibility of deadlock between clone gtid thread and 2 threads
# responsible for dropping table and flushing:
# clone gtid thread saving gtid and waiting for table cache lock in
# Gtid_table_persistor::save
# flush table thread acquired dict_sys mutex and waiting for clone gtid save to
# complete in row_quiesce_set_state
# drop table thread acquired table cache lock in tdc_remove_table and waits for
# dict_sys mutex in dict_table_close.
# Following scenario reproduces it:
# 1. First gtid is being flushed by clone GTIDs thread.
# 2. Flush table stops after taking dict_sys->mutex and waits for purge and clone
#    GTID to complete.
# 3. DROP TABLE takes exclusively all table caches and waits for dict_sys->mutex.
# 4. Clone GTIDs thread waits for table cache to close gtid_executed table.
#

--source include/have_debug.inc

# Save the initial number of concurrent sessions
--source include/count_sessions.inc

# Make sure GTID mode is on
SELECT @@GLOBAL.gtid_mode;
SELECT @@GLOBAL.enforce_gtid_consistency;

connect(con1, localhost, root,,);
connect(con2, localhost, root,,);

CREATE TABLE t1 (c1 INT, c2 INT) engine=innodb;
CREATE TABLE t2 (c1 INT, c2 INT) engine=innodb;

# Add some data and stop in the middle of gtid save.
SET GLOBAL DEBUG='+d,syncpoint_gtid_save';
INSERT INTO t1 VALUES(2,2);
SET DEBUG_SYNC='now WAIT_FOR reached_gtid_save';
SET GLOBAL DEBUG='-d,syncpoint_gtid_save';

# Use the tables (to open them and create TABLE_SHARE) to have following
# DROP TABLE something to close.
SELECT * FROM t1;
SELECT * FROM t2;

# Stop flush after taking dict_sys mutex
--connection con1
SET DEBUG_SYNC='before_purge_run SIGNAL reached_before_purge_run
WAIT_FOR continue_purge_run';
--send FLUSH TABLE t1 FOR EXPORT

--connection default
SET DEBUG_SYNC='now WAIT_FOR reached_before_purge_run';

# DROP TABLE takes the lock to table cache of all tables and signals GTID
# clone thread continue and FLUSH continue.
--connection con2
SET DEBUG_SYNC='rm_table_tdc_locked SIGNAL reached_rm_table_tdc_locked
WAIT_FOR continue_rm_table';
--send DROP TABLE t2

--connection default
SET DEBUG_SYNC='now WAIT_FOR reached_rm_table_tdc_locked';
SET DEBUG_SYNC='now SIGNAL continue_gtid_save,continue_purge_run,continue_rm_table';

# Wait for FLUSH TABLE t1 FOR EXPORT; to end
--connection con1
--reap

# Wait for DROP TABLE t2; to end
--connection con2
--reap

# Cleanup
--connection default
--disconnect con1
--disconnect con2

SET DEBUG_SYNC='RESET';

DROP TABLE t1;

--source include/wait_until_count_sessions.inc
